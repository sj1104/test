巨大嵌入模型训练
=============================

嵌入模型被认为是高维数据的有效学习范式。然而，嵌入模型的一个公开问题在于其表示（潜在因素）往往会导致较大的参数空间。我们观察到现有的分布式训练框架面临着嵌入模型的可伸缩性问题，因为从服务器更新和检索共享的嵌入参数通常主导着训练周期。

我们提出了一个新的系统框架，显著提高了大型嵌入模型训练的可扩展性。我们将嵌入的受欢迎度分布的偏差视为一个性能机会，并利用它通过嵌入缓存解决通信瓶颈。为了确保缓存之间的一致性，我们在系统设计中加入了一个新的一致性模型，它在每个嵌入的基础上提供细粒度的一致性保证。

![](hugeemb.jpg)

[comment]: # (与之前只允许过时读操作的工作相比，我们的系统还将过时用于写操作。对六项代表性任务的评估表明，与最先进的基线相比，它实现了高达88%的嵌入通信减少和高达20.68倍的性能加速。)



评估表明，与最先进的基线相比，它实现了高达80%的嵌入通信减少和高达20倍的性能加速。

<div class="warning">
<em>我们的论文已被VLDB 2022接受，我们将尽快公布全部内容。</em>
</div>
